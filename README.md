# ArXiv è®ºæ–‡è‡ªåŠ¨æŠ“å–å·¥å…·

> ğŸš€ ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ ArXiv è®ºæ–‡è‡ªåŠ¨æŠ“å–å·¥å…·ï¼Œé›†æˆ AI æ™ºèƒ½åˆ†æï¼Œæ”¯æŒè‡ªåŠ¨æ€»ç»“ã€ç¿»è¯‘ã€æ´å¯Ÿæå–å’Œé‚®ä»¶æ¨é€ã€‚

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

## âœ¨ ç‰¹æ€§

- ğŸ” **æ™ºèƒ½æœç´¢**ï¼šæ”¯æŒå…³é”®è¯ã€åˆ†ç±»ã€æ—¶é—´èŒƒå›´ç­‰å¤šç»´åº¦ç­›é€‰
- ğŸ¤– **AI åˆ†æ**ï¼šé›†æˆ OpenAI/Claude/Ollamaï¼Œæä¾›ç»“æ„åŒ–æ€»ç»“
- ğŸ’¡ **å…³é”®æ´å¯Ÿ**ï¼šAI è‡ªåŠ¨æå–è®ºæ–‡æ ¸å¿ƒåˆ›æ–°ç‚¹å’ŒæŠ€æœ¯äº®ç‚¹
- ğŸ“§ **çµæ´»æ¨é€**ï¼šæ”¯æŒé‚®ä»¶ï¼ˆå¸¦é‡è¯•ï¼‰å’Œ Webhook ä¸¤ç§æ¨é€æ–¹å¼
- â° **å®šæ—¶ä»»åŠ¡**ï¼šæ”¯æŒ Cron å¼å®šæ—¶è‡ªåŠ¨æŠ“å–
- ğŸ³ **Docker æ”¯æŒ**ï¼šä¸€é”®éƒ¨ç½²ï¼Œå¼€ç®±å³ç”¨
- ğŸ¨ **è‡ªå®šä¹‰Prompt**ï¼šå¯è‡ªå®šä¹‰AIåˆ†æç»´åº¦å’Œè¾“å‡ºæ ¼å¼
- ğŸ§¹ **è‡ªåŠ¨æ¸…ç†**ï¼šé‚®ä»¶å‘é€æˆåŠŸåè‡ªåŠ¨åˆ é™¤æœ¬åœ°æ–‡ä»¶

## å¿«é€Ÿå¼€å§‹

### Docker éƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd paper-agent

# 2. é…ç½®
cp config.yaml.template config.yaml
# ç¼–è¾‘ config.yaml å¡«å…¥ä½ çš„é…ç½®

# 3. å¯åŠ¨
docker-compose up -d
```

### æœ¬åœ°éƒ¨ç½²

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. é…ç½®
cp config.yaml.template config.yaml
# ç¼–è¾‘ config.yaml

# 3. è¿è¡Œ
python main.py
```

## ğŸ“‹ è¯¦ç»†é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ä½¿ç”¨ YAML æ ¼å¼ï¼Œæ‰€æœ‰é…ç½®é¡¹éƒ½æœ‰è¯¦ç»†è¯´æ˜ã€‚å»ºè®®å…ˆå¤åˆ¶ `config.yaml.template` ä¸º `config.yaml`ï¼Œç„¶åæ ¹æ®éœ€è¦ä¿®æ”¹ã€‚

### 1. ArXiv è®ºæ–‡æœç´¢é…ç½®

æ§åˆ¶å¦‚ä½•ä» ArXiv æœç´¢å’Œç­›é€‰è®ºæ–‡ã€‚

```yaml
arxiv:
  # æœç´¢å…³é”®è¯ï¼ˆå¤šä¸ªå…³é”®è¯ä¹‹é—´æ˜¯ORå…³ç³»ï¼‰
  keywords:
    - "machine learning"
    - "deep learning"
    - "neural network"

  # ArXiv åˆ†ç±»ä»£ç ï¼ˆå¤šä¸ªåˆ†ç±»ä¹‹é—´æ˜¯ORå…³ç³»ï¼‰
  # å¸¸ç”¨åˆ†ç±»ï¼šcs.AI (äººå·¥æ™ºèƒ½), cs.LG (æœºå™¨å­¦ä¹ ), cs.CV (è®¡ç®—æœºè§†è§‰), cs.CL (è‡ªç„¶è¯­è¨€å¤„ç†)
  # å®Œæ•´åˆ—è¡¨ï¼šhttps://arxiv.org/category_taxonomy
  categories:
    - "cs.AI"
    - "cs.LG"

  # æ¯æ¬¡æŠ“å–çš„æœ€å¤§è®ºæ–‡æ•°é‡
  max_results: 50

  # æ’åºæ–¹å¼ï¼šsubmittedDate (æäº¤æ—¥æœŸ), lastUpdatedDate (æœ€åæ›´æ–°æ—¥æœŸ), relevance (ç›¸å…³æ€§)
  sort_by: "submittedDate"

  # æ’åºé¡ºåºï¼šdescending (é™åºï¼Œæœ€æ–°çš„åœ¨å‰), ascending (å‡åºï¼Œæœ€æ—§çš„åœ¨å‰)
  sort_order: "descending"
```

**é…ç½®æŠ€å·§**ï¼š
- **å…³é”®è¯æœç´¢**ï¼šä½¿ç”¨è‹±æ–‡å…³é”®è¯ï¼Œæ”¯æŒå¼•å·åŒ…è£¹ç²¾ç¡®åŒ¹é…
- **åˆ†ç±»ç­›é€‰**ï¼šæ¨èä½¿ç”¨åˆ†ç±»+å…³é”®è¯ç»„åˆï¼Œæé«˜ç»“æœç²¾å‡†åº¦
- **æ•°é‡æ§åˆ¶**ï¼šå»ºè®®æ ¹æ®AIå¤„ç†æˆæœ¬æ§åˆ¶ `max_results`ï¼ˆæ¯ç¯‡çº¦æ¶ˆè€—1000 tokensï¼‰

### 2. å­˜å‚¨é…ç½®

æ§åˆ¶è®ºæ–‡æ•°æ®çš„ä¿å­˜æ–¹å¼å’Œä½ç½®ã€‚

```yaml
storage:
  # æ•°æ®ä¿å­˜ç›®å½•
  data_dir: "./data/papers"

  # ä¿å­˜æ ¼å¼ï¼šjson, csv, both
  format: "both"

  # æ˜¯å¦ä¸‹è½½ PDFï¼ˆä¼šæ˜¾è‘—å¢åŠ è¿è¡Œæ—¶é—´å’Œå­˜å‚¨ç©ºé—´ï¼‰
  download_pdf: false

  # PDF ä¿å­˜ç›®å½•ï¼ˆä»…å½“ download_pdf ä¸º true æ—¶æœ‰æ•ˆï¼‰
  pdf_dir: "./data/pdfs"

  # é‚®ä»¶å‘é€æˆåŠŸåè‡ªåŠ¨åˆ é™¤æœ¬åœ°æ–‡ä»¶
  # å¯ç”¨åä¼šåˆ é™¤ papers æ–‡ä»¶ï¼ˆJSON/CSVï¼‰å’Œ reports æ–‡ä»¶ï¼ˆMarkdownï¼‰
  auto_cleanup: true
```

**é…ç½®å»ºè®®**ï¼š
- **download_pdf**: é™¤éç‰¹åˆ«éœ€è¦ï¼Œå»ºè®®è®¾ä¸º `false`ï¼ˆå¯é€šè¿‡ PDF é“¾æ¥åœ¨çº¿æŸ¥çœ‹ï¼‰
- **auto_cleanup**: å®šæ—¶ä»»åŠ¡åœºæ™¯å»ºè®®å¯ç”¨ï¼Œé¿å…ç£ç›˜å æ»¡

### 3. AI åŠŸèƒ½é…ç½®

é…ç½® AI æœåŠ¡æä¾›å•†å’ŒåŠŸèƒ½å¼€å…³ã€‚

#### 3.1 åŸºç¡€é…ç½®

```yaml
ai:
  # æ˜¯å¦å¯ç”¨ AI åŠŸèƒ½ï¼ˆå…³é—­åä»…æŠ“å–åŸå§‹æ•°æ®ï¼‰
  enabled: true

  # AI æœåŠ¡æä¾›å•†ï¼šopenai, anthropic (Claude), ollama
  provider: "openai"

  # æ˜¯å¦å¯ç”¨è®ºæ–‡æ€»ç»“ï¼ˆ4ä¸ªç»´åº¦ï¼šæ ¸å¿ƒè§‚ç‚¹ã€ç ”ç©¶æ–¹æ³•ã€å…³é”®ç»“æœã€åº”ç”¨ä»·å€¼ï¼‰
  enable_summary: true

  # æ˜¯å¦ç¿»è¯‘æ‘˜è¦ä¸ºä¸­æ–‡
  enable_translation: true

  # æ˜¯å¦æå–å…³é”®æ´å¯Ÿï¼ˆ3-5ä¸ªæ ¸å¿ƒåˆ›æ–°ç‚¹ï¼‰
  enable_insights: true

  # ========== AI æ™ºèƒ½ç­›é€‰ï¼ˆæ–°åŠŸèƒ½ï¼‰ ==========
  # æ˜¯å¦å¯ç”¨ AI æ™ºèƒ½ç­›é€‰ï¼ˆåœ¨å¤„ç†å‰è¿‡æ»¤ä¸ç›¸å…³è®ºæ–‡ï¼‰
  enable_filter: true

  # AI ç­›é€‰å…³é”®è¯ï¼ˆç”¨äºåˆ¤æ–­è®ºæ–‡ç›¸å…³æ€§ï¼‰
  # ç¤ºä¾‹ï¼š" å¼ºåŒ–å­¦ä¹ åœ¨æ¸¸æˆä¸­çš„åº”ç”¨, å¤šæ™ºèƒ½ä½“ååŒ, æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¼˜åŒ–"
  filter_keywords: "å¼ºåŒ–å­¦ä¹ åº”ç”¨, æ¸¸æˆAI, å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ"

  # AI ç­›é€‰ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼Œåªä¿ç•™ç½®ä¿¡åº¦é«˜äºæ­¤å€¼çš„è®ºæ–‡ï¼‰
  # å»ºè®®å€¼ï¼š0.6-0.8ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼
  # 0.6 - å®½æ¾ï¼ˆä¿ç•™è¾ƒå¤šè®ºæ–‡ï¼‰
  # 0.7 - å¹³è¡¡ï¼ˆæ¨èï¼‰
  # 0.8 - ä¸¥æ ¼ï¼ˆåªä¿ç•™é«˜åº¦ç›¸å…³è®ºæ–‡ï¼‰
  filter_threshold: 0.7

  # æ˜¯å¦ç”Ÿæˆå¹¶å‘é€ Markdown æŠ¥å‘Š
  send_markdown_report: true

  # Markdown æŠ¥å‘Šä¿å­˜ç›®å½•
  markdown_dir: "./data/reports"
```

**AI æ™ºèƒ½ç­›é€‰è¯´æ˜**ï¼š
- **å·¥ä½œåŸç†**ï¼šåœ¨è®ºæ–‡æŠ“å–åã€AI å¤„ç†å‰ï¼Œå…ˆé€šè¿‡ AI åˆ¤æ–­è®ºæ–‡ä¸æ‚¨æŒ‡å®šçš„å…³é”®è¯çš„ç›¸å…³æ€§
- **ä¼˜åŠ¿**ï¼šèŠ‚çœ AI æˆæœ¬ï¼ˆåªå¤„ç†ç›¸å…³è®ºæ–‡ï¼‰+ æå‡æŠ¥å‘Šè´¨é‡ï¼ˆè¿‡æ»¤æ— å…³å†…å®¹ï¼‰
- **ä½¿ç”¨åœºæ™¯**ï¼š
  - ArXiv æœç´¢å…³é”®è¯å¤ªå®½æ³›ï¼Œè¿”å›å¾ˆå¤šä¸ç›¸å…³è®ºæ–‡
  - å¸Œæœ›èšç„¦ç‰¹å®šç ”ç©¶æ–¹å‘æˆ–åº”ç”¨åœºæ™¯
  - éœ€è¦é™ä½ AI å¤„ç†æˆæœ¬

**é…ç½®ç¤ºä¾‹**ï¼š
```yaml
# åœºæ™¯1ï¼šåªå…³æ³¨å¼ºåŒ–å­¦ä¹ åœ¨æ¸¸æˆä¸­çš„åº”ç”¨
filter_keywords: "æ¸¸æˆAI, å¼ºåŒ–å­¦ä¹ åœ¨æ¸¸æˆä¸­çš„åº”ç”¨, æ¸¸æˆæ™ºèƒ½ä½“è®­ç»ƒ"
filter_threshold: 0.75

# åœºæ™¯2ï¼šå…³æ³¨åŒ»ç–—AIçš„å¤šä¸ªæ–¹å‘
filter_keywords: "åŒ»å­¦å½±åƒè¯Šæ–­, ç–¾ç—…é¢„æµ‹, è¯ç‰©å‘ç°, AIè¾…åŠ©è¯Šç–—"
filter_threshold: 0.65

# åœºæ™¯3ï¼šä¸¥æ ¼ç­›é€‰ç‰¹å®šç®—æ³•
filter_keywords: "Transformeræ¶æ„æ”¹è¿›, æ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–"
filter_threshold: 0.8
```

#### 3.2 OpenAI é…ç½®ï¼ˆæ¨èï¼‰

```yaml
ai:
  provider: "openai"
  openai:
    # OpenAI API å¯†é’¥
    api_key: "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

    # æ¨¡å‹é€‰æ‹©
    # - gpt-3.5-turbo: ä¾¿å®œï¼Œé€Ÿåº¦å¿«ï¼Œé€‚åˆå¤§æ‰¹é‡
    # - gpt-4o-mini: æ€§ä»·æ¯”é«˜
    # - gpt-4o: è´¨é‡æœ€é«˜ï¼Œä»·æ ¼è¾ƒè´µ
    model: "gpt-3.5-turbo"

    # API ç«¯ç‚¹ï¼ˆå®˜æ–¹æˆ–ç¬¬ä¸‰æ–¹å…¼å®¹æœåŠ¡ï¼‰
    base_url: "https://api.openai.com/v1"

    # å•æ¬¡è¯·æ±‚æœ€å¤§tokenæ•°
    max_tokens: 1000

    # æ¸©åº¦å‚æ•°ï¼ˆ0-2ï¼‰ï¼Œå€¼è¶Šé«˜è¶Šéšæœº
    temperature: 0.7
```

#### 3.3 ç¡…åŸºæµåŠ¨é…ç½®ï¼ˆå›½å†…æ¨èï¼‰

ç¡…åŸºæµåŠ¨æä¾›å›½å†…å¯è®¿é—®çš„ OpenAI å…¼å®¹ APIï¼Œæ”¯æŒ DeepSeek-V3 ç­‰æ¨¡å‹ã€‚

```yaml
ai:
  provider: "openai"  # ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
  openai:
    api_key: "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"  # åœ¨ https://siliconflow.cn è·å–
    model: "deepseek-ai/DeepSeek-V3"  # æˆ– "Qwen/Qwen2.5-7B-Instruct"
    base_url: "https://api.siliconflow.cn/v1"  # æ³¨æ„ï¼šä¸è¦åŠ  /chat/completions
```

**ä¼˜åŠ¿**ï¼š
- âœ… å›½å†…ç›´è¿ï¼Œæ— éœ€é­”æ³•
- âœ… DeepSeek-V3 æˆæœ¬æä½ï¼ˆçº¦ä¸º GPT-3.5 çš„ 1/10ï¼‰
- âœ… å®Œå…¨å…¼å®¹ OpenAI API

**è·å– API Key**ï¼š
1. è®¿é—® [https://siliconflow.cn](https://siliconflow.cn)
2. æ³¨å†Œå¹¶ç™»å½•
3. åœ¨ API Keys é¡µé¢åˆ›å»ºå¯†é’¥
4. å¤åˆ¶å¯†é’¥åˆ°é…ç½®æ–‡ä»¶

#### 3.4 Claude é…ç½®

```yaml
ai:
  provider: "anthropic"
  anthropic:
    api_key: "sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    model: "claude-3-5-sonnet-20241022"  # æˆ– "claude-3-5-haiku-20241022"
    base_url: "https://api.anthropic.com/v1"
    max_tokens: 1000
    temperature: 0.7
```

**æ¨¡å‹é€‰æ‹©**ï¼š
- **claude-3-5-sonnet**: è´¨é‡æœ€é«˜ï¼Œé€‚åˆå­¦æœ¯åˆ†æ
- **claude-3-5-haiku**: é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½

#### 3.5 Ollama æœ¬åœ°é…ç½®

ä½¿ç”¨æœ¬åœ°è¿è¡Œçš„ Ollamaï¼Œå®Œå…¨å…è´¹ï¼Œæ— éœ€ API å¯†é’¥ã€‚

```yaml
ai:
  provider: "ollama"
  ollama:
    model: "llama2"  # æˆ– "qwen2.5:7b", "deepseek-r1:7b"
    base_url: "http://localhost:11434"
```

**å‰ç½®è¦æ±‚**ï¼š
1. å®‰è£… Ollamaï¼šhttps://ollama.ai
2. æ‹‰å–æ¨¡å‹ï¼š`ollama pull llama2`
3. å¯åŠ¨æœåŠ¡ï¼š`ollama serve`

**ä¼˜åŠ¿**ï¼šå®Œå…¨å…è´¹ï¼Œæ•°æ®æœ¬åœ°å¤„ç†ï¼Œéšç§æ€§å¥½
**åŠ£åŠ¿**ï¼šéœ€è¦æœ¬åœ°ç®—åŠ›ï¼Œè´¨é‡ä¸å¦‚äº‘ç«¯å¤§æ¨¡å‹

### 4. é€šçŸ¥é…ç½®

é…ç½®å¦‚ä½•æ¥æ”¶è®ºæ–‡æŠ¥å‘Šã€‚

#### 4.1 é‚®ä»¶é€šçŸ¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

```yaml
notification:
  # æ˜¯å¦å¯ç”¨é€šçŸ¥
  enabled: true

  # é€šçŸ¥æ–¹å¼ï¼šemail æˆ– webhook
  method: "email"

  # é‚®ä»¶é…ç½®
  email:
    # SMTP æœåŠ¡å™¨åœ°å€
    smtp_server: "smtp.gmail.com"

    # SMTP ç«¯å£ï¼ˆä¸€èˆ¬æ˜¯ 587 æˆ– 465ï¼‰
    smtp_port: 587

    # å‘ä»¶äººé‚®ç®±
    sender: "your-email@gmail.com"

    # é‚®ç®±å¯†ç æˆ–åº”ç”¨ä¸“ç”¨å¯†ç 
    password: "your-app-password"

    # æ”¶ä»¶äººåˆ—è¡¨ï¼ˆå¯ä»¥å¤šä¸ªï¼‰
    recipients:
      - "recipient1@example.com"
      - "recipient2@example.com"
```

**é‡è¦è¯´æ˜**ï¼š

**Gmail é…ç½®**ï¼š
1. å¼€å¯ä¸¤æ­¥éªŒè¯ï¼šhttps://myaccount.google.com/security
2. ç”Ÿæˆåº”ç”¨ä¸“ç”¨å¯†ç ï¼šhttps://myaccount.google.com/apppasswords
3. ä½¿ç”¨ç”Ÿæˆçš„16ä½å¯†ç ï¼ˆæ ¼å¼ï¼šxxxx xxxx xxxx xxxxï¼‰

**QQ é‚®ç®±é…ç½®**ï¼š
```yaml
email:
  smtp_server: "smtp.qq.com"
  smtp_port: 587
  sender: "your-qq@qq.com"
  password: "æˆæƒç "  # åœ¨QQé‚®ç®±è®¾ç½®-è´¦æˆ·ä¸­è·å–æˆæƒç 
```

**163 é‚®ç®±é…ç½®**ï¼š
```yaml
email:
  smtp_server: "smtp.163.com"
  smtp_port: 465
  sender: "your-email@163.com"
  password: "æˆæƒç "  # åœ¨é‚®ç®±è®¾ç½®ä¸­è·å–æˆæƒç 
```

**é‡è¯•æœºåˆ¶**ï¼šé‚®ä»¶å‘é€å¤±è´¥æ—¶ä¼šè‡ªåŠ¨é‡è¯• 3 æ¬¡ï¼Œæ¯æ¬¡é—´éš” 5 ç§’ã€‚

#### 4.2 Webhook é€šçŸ¥ï¼ˆæ¨èï¼‰

å¦‚æœé‚®ä»¶å‘é€ç»å¸¸è¶…æ—¶ï¼Œå»ºè®®æ”¹ç”¨ Webhook æ–¹å¼ã€‚

```yaml
notification:
  enabled: true
  method: "webhook"

  webhook:
    # Webhook æ¥æ”¶åœ°å€
    url: "https://your-api.example.com/arxiv/report"

    # HTTP æ–¹æ³•
    method: "POST"
```

**Webhook è¯·æ±‚æ ¼å¼**ï¼š
```json
{
  "type": "arxiv_report",
  "timestamp": "20260113_120000",
  "paper_count": 5,
  "content": "# ArXiv è®ºæ–‡æ—¥æŠ¥\n\n...",
  "format": "markdown"
}
```

**é€‚ç”¨åœºæ™¯**ï¼š
- ä¼ä¸šå¾®ä¿¡/é’‰é’‰æœºå™¨äºº
- Slack/Discord é€šçŸ¥
- è‡ªå»ºæœåŠ¡æ¥æ”¶å¤„ç†

### 5. å®šæ—¶ä»»åŠ¡é…ç½®

é…ç½®è‡ªåŠ¨æ‰§è¡Œæ—¶é—´ã€‚

```yaml
schedule:
  # æ˜¯å¦å¯ç”¨å®šæ—¶ä»»åŠ¡
  enabled: true

  # æ‰§è¡Œæ—¶é—´ï¼ˆ24å°æ—¶åˆ¶ï¼‰
  time: "09:00"

  # æ˜¯å¦åœ¨å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡
  run_on_start: false
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
# ä»¥å®šæ—¶ä»»åŠ¡æ¨¡å¼å¯åŠ¨ï¼ˆä¼šä¸€ç›´è¿è¡Œï¼‰
python main.py --schedule

# æˆ–è€…ä½¿ç”¨ç³»ç»Ÿ crontabï¼ˆLinux/Macï¼‰
crontab -e
# æ·»åŠ ï¼š0 9 * * * cd /path/to/paper-agent && python main.py
```

### 6. æ—¥å¿—é…ç½®

æ§åˆ¶æ—¥å¿—è¾“å‡ºå’Œå­˜å‚¨ã€‚

```yaml
logging:
  # æ—¥å¿—çº§åˆ«ï¼šDEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"

  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
  file: "./logs/arxiv_scraper.log"

  # æ˜¯å¦åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
  console: true

  # æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆMBï¼‰
  max_size: 10

  # ä¿ç•™çš„æ—¥å¿—æ–‡ä»¶æ•°é‡ï¼ˆæ—¥å¿—è½®è½¬ï¼‰
  backup_count: 5
```

**æ—¥å¿—çº§åˆ«è¯´æ˜**ï¼š
- **DEBUG**: è¯¦ç»†è°ƒè¯•ä¿¡æ¯ï¼ˆå¼€å‘æ—¶ä½¿ç”¨ï¼‰
- **INFO**: ä¸€èˆ¬ä¿¡æ¯ï¼ˆæ¨èï¼‰
- **WARNING**: è­¦å‘Šä¿¡æ¯
- **ERROR**: é”™è¯¯ä¿¡æ¯
- **CRITICAL**: ä¸¥é‡é”™è¯¯

### 7. è‡ªå®šä¹‰ Promptï¼ˆé«˜çº§ï¼‰

å¯ä»¥è‡ªå®šä¹‰ AI åˆ†æçš„ç»´åº¦å’Œè¾“å‡ºæ ¼å¼ï¼Œç¼–è¾‘ `prompts/prompts.yaml`ï¼š

```yaml
summarize:
  system: "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æä¸“å®¶ã€‚"
  user_template: |
    è¯·å¯¹ä»¥ä¸‹è®ºæ–‡è¿›è¡Œåˆ†æï¼š
    æ ‡é¢˜ï¼š{title}
    æ‘˜è¦ï¼š{summary}

    è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æï¼š
    1. æ ¸å¿ƒåˆ›æ–°ç‚¹
    2. æŠ€æœ¯æ–¹æ³•
    3. å®éªŒç»“æœ
    4. åº”ç”¨ä»·å€¼
```

è¯¦è§ï¼š[Prompt è‡ªå®šä¹‰æŒ‡å—](docs/CUSTOM_PROMPTS.md)

---

## ğŸ“ å®Œæ•´é…ç½®ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç”Ÿäº§ç¯å¢ƒçš„å®Œæ•´é…ç½®ç¤ºä¾‹ï¼š

```yaml
# ArXiv æœç´¢é…ç½®
arxiv:
  keywords: ["machine learning", "deep learning", "transformer"]
  categories: ["cs.AI", "cs.LG", "cs.CL"]
  max_results: 20
  sort_by: "submittedDate"
  sort_order: "descending"

# å­˜å‚¨é…ç½®
storage:
  data_dir: "./data/papers"
  format: "both"
  download_pdf: false
  auto_cleanup: true

# AI é…ç½®ï¼ˆä½¿ç”¨ç¡…åŸºæµåŠ¨ï¼‰
ai:
  enabled: true
  provider: "openai"
  enable_summary: true
  enable_translation: true
  enable_insights: true
  send_markdown_report: true
  markdown_dir: "./data/reports"

  openai:
    api_key: "sk-xxxxxxxx"
    model: "deepseek-ai/DeepSeek-V3"
    base_url: "https://api.siliconflow.cn/v1"

# é€šçŸ¥é…ç½®ï¼ˆä½¿ç”¨ QQ é‚®ç®±ï¼‰
notification:
  enabled: true
  method: "email"

  email:
    smtp_server: "smtp.qq.com"
    smtp_port: 587
    sender: "your-qq@qq.com"
    password: "your-auth-code"
    recipients:
      - "recipient@example.com"

# å®šæ—¶ä»»åŠ¡ï¼ˆæ¯å¤©æ—©ä¸Š9ç‚¹ï¼‰
schedule:
  enabled: true
  time: "09:00"
  run_on_start: false

# æ—¥å¿—é…ç½®
logging:
  level: "INFO"
  file: "./logs/arxiv_scraper.log"
  console: true
  max_size: 10
  backup_count: 5
```

## è¾“å‡ºè¯´æ˜

### JSON æ ¼å¼

ä¿å­˜åœ¨ `./data/papers/` ç›®å½•ï¼ŒåŒ…å«ï¼š
- è®ºæ–‡åŸºæœ¬ä¿¡æ¯
- AI æ€»ç»“
- ä¸­æ–‡ç¿»è¯‘
- å…³é”®æ´å¯Ÿ

### Markdown æŠ¥å‘Š

ä¿å­˜åœ¨ `./data/reports/` ç›®å½•ï¼ŒåŒ…å«ï¼š
- ğŸ“‹ åŸºæœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€ArXiv IDã€PDFé“¾æ¥ï¼‰
- ğŸ’¡ å…³é”®æ´å¯Ÿï¼ˆ3-5ä¸ªæ ¸å¿ƒåˆ›æ–°ç‚¹ï¼‰
- ğŸ“ åŸæ–‡æ‘˜è¦
- ğŸŒ ä¸­æ–‡ç¿»è¯‘
- ğŸ¤– AI æ™ºèƒ½æ€»ç»“ï¼ˆæ ¸å¿ƒè§‚ç‚¹ã€ç ”ç©¶æ–¹æ³•ã€å…³é”®ç»“æœã€åº”ç”¨ä»·å€¼ï¼‰

### é‚®ä»¶é€šçŸ¥

è‡ªåŠ¨å‘é€ Markdown æŠ¥å‘Šåˆ°æŒ‡å®šé‚®ç®±ï¼ŒåŒ…å«æ‰€æœ‰è®ºæ–‡çš„å®Œæ•´åˆ†æã€‚

## é¡¹ç›®ç»“æ„

```
paper-agent/
â”œâ”€â”€ config.yaml          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ main.py              # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt     # Pythonä¾èµ–
â”œâ”€â”€ Dockerfile           # Dockeré•œåƒå®šä¹‰
â”œâ”€â”€ docker-compose.yml   # Docker Composeé…ç½®
â”œâ”€â”€ src/                 # æºä»£ç 
â”‚   â”œâ”€â”€ arxiv_scraper.py    # è®ºæ–‡æŠ“å–
â”‚   â”œâ”€â”€ ai_service.py       # AIæœåŠ¡ï¼ˆæ€»ç»“/ç¿»è¯‘/æ´å¯Ÿï¼‰
â”‚   â”œâ”€â”€ markdown_generator.py  # Markdownç”Ÿæˆ
â”‚   â””â”€â”€ utils.py            # å·¥å…·å‡½æ•°
â”œâ”€â”€ data/                # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ papers/          # è®ºæ–‡JSON/CSV
â”‚   â””â”€â”€ reports/         # MarkdownæŠ¥å‘Š
â””â”€â”€ logs/                # æ—¥å¿—æ–‡ä»¶
```

## ä½¿ç”¨ç¤ºä¾‹

### å•æ¬¡è¿è¡Œ

```bash
python main.py
```

### å®šæ—¶ä»»åŠ¡æ¨¡å¼

ç¼–è¾‘ `config.yaml` å¯ç”¨å®šæ—¶ä»»åŠ¡ï¼š
```yaml
schedule:
  enabled: true
  time: "09:00"
```

ç„¶åè¿è¡Œï¼š
```bash
python main.py
```

## â“ å¸¸è§é—®é¢˜ä¸æ•…éšœæ’æŸ¥

### 1. OpenAI API è°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
AIServiceError: API è°ƒç”¨å¤±è´¥: Connection timeout
```

**å¯èƒ½åŸå› åŠè§£å†³æ–¹æ¡ˆ**ï¼š

#### é—®é¢˜1ï¼šAPI Key é”™è¯¯
```yaml
# âŒ é”™è¯¯ï¼šAPI key æ ¼å¼ä¸å¯¹
api_key: "your-api-key"

# âœ… æ­£ç¡®ï¼šåº”è¯¥æ˜¯ sk- å¼€å¤´çš„çœŸå®å¯†é’¥
api_key: "sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

#### é—®é¢˜2ï¼šbase_url é…ç½®é”™è¯¯
```yaml
# âŒ é”™è¯¯ï¼šåŒ…å«äº† /chat/completions
base_url: "https://api.openai.com/v1/chat/completions"

# âœ… æ­£ç¡®ï¼šåªåˆ° /v1
base_url: "https://api.openai.com/v1"
```

#### é—®é¢˜3ï¼šç½‘ç»œè¿æ¥é—®é¢˜
- **å®˜æ–¹ OpenAI API**ï¼šéœ€è¦ç§‘å­¦ä¸Šç½‘
- **è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨å›½å†…æœåŠ¡å•†ï¼ˆå¦‚ç¡…åŸºæµåŠ¨ï¼‰
  ```yaml
  ai:
    provider: "openai"
    openai:
      api_key: "sk-xxxxxxxx"
      base_url: "https://api.siliconflow.cn/v1"
  ```

#### é—®é¢˜4ï¼šé…é¢ä¸è¶³
- æ£€æŸ¥ OpenAI è´¦æˆ·ä½™é¢
- æŸ¥çœ‹ API ä½¿ç”¨é™åˆ¶

**è°ƒè¯•æŠ€å·§**ï¼š
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python main.py

# æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
tail -f logs/arxiv_scraper.log
```

### 2. é‚®ä»¶å‘é€å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
[Errno 110] Connection timed out
é‚®ä»¶å‘é€å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° (3)
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

#### æ–¹æ¡ˆ1ï¼šä½¿ç”¨åº”ç”¨ä¸“ç”¨å¯†ç ï¼ˆGmailï¼‰

1. è®¿é—® https://myaccount.google.com/security
2. å¼€å¯ä¸¤æ­¥éªŒè¯
3. ç”Ÿæˆåº”ç”¨ä¸“ç”¨å¯†ç ï¼šhttps://myaccount.google.com/apppasswords
4. ä½¿ç”¨ç”Ÿæˆçš„16ä½å¯†ç ï¼š

```yaml
email:
  smtp_server: "smtp.gmail.com"
  smtp_port: 587
  sender: "your-email@gmail.com"
  password: "abcd efgh ijkl mnop"  # åº”ç”¨ä¸“ç”¨å¯†ç ï¼Œå¸¦ç©ºæ ¼
```

#### æ–¹æ¡ˆ2ï¼šåˆ‡æ¢åˆ°QQé‚®ç®±

QQé‚®ç®±æ›´ç¨³å®šï¼Œæ¨èä½¿ç”¨ï¼š

```yaml
email:
  smtp_server: "smtp.qq.com"
  smtp_port: 587  # æˆ– 465ï¼ˆSSLï¼‰
  sender: "your-qq@qq.com"
  password: "æˆæƒç "  # ä¸æ˜¯QQå¯†ç ï¼
```

**è·å–QQé‚®ç®±æˆæƒç **ï¼š
1. ç™»å½• QQ é‚®ç®±
2. è®¾ç½® â†’ è´¦æˆ· â†’ å¼€å¯ SMTP æœåŠ¡
3. ç”Ÿæˆæˆæƒç 
4. å¤åˆ¶æˆæƒç åˆ°é…ç½®æ–‡ä»¶

#### æ–¹æ¡ˆ3ï¼šæ”¹ç”¨Webhookï¼ˆæœ€ç¨³å®šï¼‰

å¦‚æœé‚®ä»¶æŒç»­å¤±è´¥ï¼Œå»ºè®®ä½¿ç”¨ Webhookï¼š

```yaml
notification:
  enabled: true
  method: "webhook"
  webhook:
    url: "https://your-webhook-url.com/arxiv"
    method: "POST"
```

**æ­å»ºç®€å•çš„ Webhook æ¥æ”¶æœåŠ¡**ï¼š
```python
# webhook_server.py
from flask import Flask, request
app = Flask(__name__)

@app.route('/arxiv', methods=['POST'])
def receive_report():
    data = request.json
    content = data['content']
    # ä¿å­˜åˆ°æ–‡ä»¶æˆ–å‘é€åˆ°å…¶ä»–æœåŠ¡
    with open('report.md', 'w') as f:
        f.write(content)
    return {'status': 'ok'}

if __name__ == '__main__':
    app.run(port=5000)
```

### 3. é…ç½®æ–‡ä»¶è§£æé”™è¯¯

**ç—‡çŠ¶**ï¼š
```
yaml.scanner.ScannerError: mapping values are not allowed here
```

**åŸå› **ï¼šYAML æ ¼å¼é”™è¯¯

**å¸¸è§é”™è¯¯**ï¼š

```yaml
# âŒ é”™è¯¯ï¼šç¼©è¿›ä¸ä¸€è‡´
ai:
  enabled: true
 provider: "openai"  # ç¼©è¿›å°‘äº†ä¸€ä¸ªç©ºæ ¼

# âœ… æ­£ç¡®ï¼šç¼©è¿›å¯¹é½
ai:
  enabled: true
  provider: "openai"
```

```yaml
# âŒ é”™è¯¯ï¼šå†’å·åæ²¡æœ‰ç©ºæ ¼
smtp_server:"smtp.gmail.com"

# âœ… æ­£ç¡®ï¼šå†’å·åè¦æœ‰ç©ºæ ¼
smtp_server: "smtp.gmail.com"
```

```yaml
# âŒ é”™è¯¯ï¼šå­—ç¬¦ä¸²åŒ…å«ç‰¹æ®Šå­—ç¬¦æœªåŠ å¼•å·
password: xxx@123

# âœ… æ­£ç¡®ï¼šåŒ…å«ç‰¹æ®Šå­—ç¬¦è¦åŠ å¼•å·
password: "xxx@123"
```

**éªŒè¯é…ç½®æ–‡ä»¶**ï¼š
```bash
# ä½¿ç”¨ Python éªŒè¯ YAML è¯­æ³•
python -c "import yaml; yaml.safe_load(open('config.yaml'))"
```

### 4. æ‰¾ä¸åˆ°è®ºæ–‡

**ç—‡çŠ¶**ï¼š
```
æˆåŠŸè·å– 0 ç¯‡è®ºæ–‡
```

**å¯èƒ½åŸå› **ï¼š

#### åŸå› 1ï¼šå…³é”®è¯å¤ªç²¾ç¡®
```yaml
# âŒ å¤ªç²¾ç¡®ï¼Œå¯èƒ½æ‰¾ä¸åˆ°
keywords: ["very specific long tail keyword combination"]

# âœ… ä½¿ç”¨å¸¸è§æœ¯è¯­
keywords: ["machine learning", "deep learning"]
```

#### åŸå› 2ï¼šåˆ†ç±»å’Œå…³é”®è¯å†²çª
```yaml
# âŒ åŒ»å­¦å…³é”®è¯ + è®¡ç®—æœºåˆ†ç±»
keywords: ["cancer treatment"]
categories: ["cs.AI"]  # ä¸åŒ¹é…

# âœ… å…³é”®è¯å’Œåˆ†ç±»åŒ¹é…
keywords: ["medical AI", "diagnosis"]
categories: ["cs.AI", "cs.CV"]
```

#### åŸå› 3ï¼šæ—¶é—´èŒƒå›´å¤ªçª„
- ArXiv æ¯å¤©æ–°å¢è®ºæ–‡æœ‰é™
- å»ºè®®è®¾ç½®åˆç†çš„ `max_results`

**æµ‹è¯•æœç´¢**ï¼š
```bash
# ä½¿ç”¨å®½æ³›çš„æ¡ä»¶æµ‹è¯•
python main.py
# æŸ¥çœ‹æ—¥å¿—ä¸­çš„æŸ¥è¯¢å­—ç¬¦ä¸²
```

### 5. AI å¤„ç†é€Ÿåº¦æ…¢

**ä¼˜åŒ–å»ºè®®**ï¼š

#### 1. å‡å°‘è®ºæ–‡æ•°é‡
```yaml
arxiv:
  max_results: 10  # ä» 50 é™åˆ° 10
```

#### 2. å…³é—­ä¸éœ€è¦çš„åŠŸèƒ½
```yaml
ai:
  enable_summary: true
  enable_translation: false  # å¦‚æœä¸éœ€è¦ç¿»è¯‘ï¼Œå…³é—­
  enable_insights: false     # å¦‚æœä¸éœ€è¦æ´å¯Ÿï¼Œå…³é—­
```

#### 3. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
```yaml
openai:
  model: "gpt-3.5-turbo"  # æ¯” gpt-4 å¿«å¾—å¤š
```

#### 4. ä½¿ç”¨æœ¬åœ°æ¨¡å‹
```yaml
ai:
  provider: "ollama"
  ollama:
    model: "qwen2.5:7b"  # æœ¬åœ°è¿è¡Œï¼Œé€Ÿåº¦å¿«
```

### 6. Docker éƒ¨ç½²é—®é¢˜

#### é—®é¢˜1ï¼šå®¹å™¨æ— æ³•å¯åŠ¨
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
docker-compose logs -f

# é‡æ–°æ„å»ºé•œåƒ
docker-compose build --no-cache

# åˆ é™¤æ—§å®¹å™¨é‡æ–°åˆ›å»º
docker-compose down
docker-compose up -d
```

#### é—®é¢˜2ï¼šæ— æ³•è®¿é—®å¤–éƒ¨ç½‘ç»œ
```bash
# æ£€æŸ¥ Docker ç½‘ç»œ
docker network ls

# ä½¿ç”¨ host ç½‘ç»œæ¨¡å¼ï¼ˆLinuxï¼‰
docker run --network host ...
```

#### é—®é¢˜3ï¼šé…ç½®æ–‡ä»¶æœªæŒ‚è½½
```yaml
# docker-compose.yml
volumes:
  - ./config.yaml:/app/config.yaml:ro  # ç¡®ä¿æŒ‚è½½é…ç½®æ–‡ä»¶
  - ./data:/app/data
```

### 7. æƒé™é—®é¢˜ï¼ˆLinux/Macï¼‰

**ç—‡çŠ¶**ï¼š
```
PermissionError: [Errno 13] Permission denied: './data/papers'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä¿®æ”¹ç›®å½•æƒé™
chmod -R 755 data logs

# æˆ–ä½¿ç”¨å½“å‰ç”¨æˆ·è¿è¡Œ Docker
docker-compose run --user $(id -u):$(id -g) paper-agent
```

### 8. ä¸­æ–‡ä¹±ç 

**ç—‡çŠ¶**ï¼šMarkdown æŠ¥å‘Šæˆ–é‚®ä»¶ä¸­æ–‡æ˜¾ç¤ºä¸ºä¹±ç 

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. ç¡®ä¿é…ç½®æ–‡ä»¶ä½¿ç”¨ UTF-8 ç¼–ç ä¿å­˜
2. æ£€æŸ¥ç»ˆç«¯ç¼–ç è®¾ç½®
3. é‚®ä»¶å®¢æˆ·ç«¯è®¾ç½®ä¸º UTF-8 æ˜¾ç¤º

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶ç¼–ç 
file -i config.yaml
# åº”æ˜¾ç¤ºï¼šcharset=utf-8
```

### 9. è·å–å¸®åŠ©

å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æ— æ³•è§£å†³é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**ï¼š
   ```bash
   tail -n 100 logs/arxiv_scraper.log
   ```

2. **å¯ç”¨è°ƒè¯•æ¨¡å¼**ï¼š
   ```yaml
   logging:
     level: "DEBUG"  # è¾“å‡ºè¯¦ç»†æ—¥å¿—
   ```

3. **æäº¤ Issue**ï¼š
   - æä¾›é…ç½®æ–‡ä»¶ï¼ˆéšå»æ•æ„Ÿä¿¡æ¯ï¼‰
   - æä¾›é”™è¯¯æ—¥å¿—
   - è¯´æ˜è¿è¡Œç¯å¢ƒï¼ˆOSã€Pythonç‰ˆæœ¬ç­‰ï¼‰

4. **ç¤¾åŒºæ”¯æŒ**ï¼š
   - GitHub Issues: [é¡¹ç›®åœ°å€]/issues
   - åŒ…å«å°½å¯èƒ½è¯¦ç»†çš„ä¿¡æ¯

## API æˆæœ¬ä¼°ç®—

ä»¥ OpenAI GPT-3.5-turbo ä¸ºä¾‹ï¼ˆæ¯ç¯‡è®ºæ–‡ï¼‰ï¼š
- æ€»ç»“ï¼šçº¦ 500 tokens
- ç¿»è¯‘ï¼šçº¦ 300 tokens
- æ´å¯Ÿæå–ï¼šçº¦ 200 tokens
- **æ€»è®¡**ï¼šçº¦ 1000 tokens â‰ˆ \$0.002

50ç¯‡è®ºæ–‡ â‰ˆ \$0.10ï¼ˆçº¦0.7å…ƒï¼‰

ä½¿ç”¨ç¡…åŸºæµåŠ¨ API å¯æ˜¾è‘—é™ä½æˆæœ¬ï¼ˆDeepSeek-V3 æ›´ä¾¿å®œï¼‰ã€‚

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼
